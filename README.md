# ç³»ç»Ÿç›‘æ§AIåŠ©ç†

ä¸€ä¸ªç”¨äºå­¦ä¹ çš„è½»é‡çº§AIåŠ©ç†ï¼Œèƒ½å¤Ÿç›‘æ§ç³»ç»Ÿæ€§èƒ½å¹¶é€šè¿‡LLMæä¾›ä¼˜åŒ–å»ºè®®ã€‚

## ğŸ¯ åŠŸèƒ½ç‰¹æ€§

- âœ… **ç³»ç»Ÿç›‘æ§**: å®æ—¶ç›‘æ§CPUã€å†…å­˜ã€ç£ç›˜ã€ç½‘ç»œä½¿ç”¨æƒ…å†µ
- âœ… **AIå»ºè®®**: åŸºäºç³»ç»ŸçŠ¶æ€è‡ªåŠ¨ç”Ÿæˆä¼˜åŒ–å»ºè®®
- âœ… **å¯¹è¯åŠŸèƒ½**: æ”¯æŒä¸AIè¿›è¡Œç³»ç»Ÿä¼˜åŒ–ç›¸å…³çš„å¯¹è¯
- âœ… **å†å²è®°å½•**: ä¿å­˜å’Œç®¡ç†å¯¹è¯å†å²
- âœ… **å‘Šè­¦åŠŸèƒ½**: å½“ç³»ç»ŸæŒ‡æ ‡è¶…è¿‡é˜ˆå€¼æ—¶å‘å‡ºå‘Šè­¦

## ğŸ“ é¡¹ç›®ç»“æ„

```
system_analysis/
â”œâ”€â”€ main.py                     # æ—§ç‰ˆä¸»å…¥å£ï¼ˆå·²åºŸå¼ƒï¼‰
â”œâ”€â”€ core/                       # æ ¸å¿ƒåŠŸèƒ½æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py            # æ¨¡å—å¯¼å‡º
â”‚   â”œâ”€â”€ system_monitor.py      # ç³»ç»Ÿç›‘æ§
â”‚   â”œâ”€â”€ advisor.py             # AIå»ºè®®å¼•æ“
â”‚   â”œâ”€â”€ history_manager.py     # å†å²è®°å½•ç®¡ç†
â”‚   â””â”€â”€ utils.py               # å·¥å…·å‡½æ•°
â”œâ”€â”€ config/                     # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ settings.json          # ç³»ç»Ÿé…ç½®
â”œâ”€â”€ data/                       # æ•°æ®å­˜å‚¨
â”‚   â””â”€â”€ history.json           # å¯¹è¯å†å²
â”œâ”€â”€ tests/                      # æµ‹è¯•æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
â””â”€â”€ README.md                   # é¡¹ç›®è¯´æ˜
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install psutil openai
```

### 2. é…ç½®API Key

ç¼–è¾‘ `config/settings.json`ï¼Œå¡«å…¥ä½ çš„OpenAI API Keyï¼š

```json
{
  "llm": {
    "api_key": "your-actual-api-key",
    "model": "gpt-3.5-turbo",
    "base_url": "https://api.openai.com/v1"
  }
}
```

### 3. åŸºç¡€ä½¿ç”¨ç¤ºä¾‹

è¿è¡Œexample.py

```python
from core import (
    get_status,
    auto_advise,
    user_advise,
    get_history_list,
    switch_conversation,
    create_conversation
)

# 1. è·å–ç³»ç»ŸçŠ¶æ€
status = get_status()
print(f"CPU: {status['cpu']}%")
print(f"å†…å­˜: {status['memory']}%")
print(f"æ‘˜è¦: {status['summary']}")

# 2. è·å–AIå»ºè®®
conv_id, advice = auto_advise(status)
print(f"\nå»ºè®®:\n{advice}")

# 3. ä¸AIå¯¹è¯
response = user_advise(conv_id, "å¦‚ä½•é™ä½CPUä½¿ç”¨ç‡ï¼Ÿ")
print(f"\nAIå›å¤:\n{response}")

# 4. æŸ¥çœ‹å†å²å¯¹è¯
history = get_history_list()
for conv in history:
    print(f"- [{conv['id']}] {conv['title']}")

# 5. åˆ‡æ¢å¯¹è¯
messages = switch_conversation(conv_id)
for msg in messages:
    print(f"{msg['role']}: {msg['content'][:50]}...")
```

## ğŸ“š æ ¸å¿ƒAPIæ–‡æ¡£

### ç³»ç»Ÿç›‘æ§ (`system_monitor.py`)

#### `get_status() -> Dict[str, Any]`
è·å–ç³»ç»ŸçŠ¶æ€ä¿¡æ¯

**è¿”å›å€¼:**
```python
{
    "cpu": 72.5,              # CPUä½¿ç”¨ç‡(%)
    "memory": 65.3,           # å†…å­˜ä½¿ç”¨ç‡(%)
    "disk": 45.8,             # ç£ç›˜ä½¿ç”¨ç‡(%)
    "network_sent": 1024000,  # ç½‘ç»œå‘é€å­—èŠ‚
    "network_recv": 2048000,  # ç½‘ç»œæ¥æ”¶å­—èŠ‚
    "summary": "ç³»ç»Ÿè¿è¡Œæ­£å¸¸",
    "timestamp": "2024-10-25 14:30:22",
    "details": { ... }        # è¯¦ç»†ä¿¡æ¯
}
```

#### `get_top_processes(limit: int = 5) -> List[Dict]`
è·å–å ç”¨èµ„æºæœ€å¤šçš„è¿›ç¨‹

#### `check_alerts(status: Dict, thresholds: Dict = None) -> List[str]`
æ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦å‘Šè­¦çš„æŒ‡æ ‡

### AIå»ºè®® (`advisor.py`)

#### `auto_advise(status: Dict[str, Any]) -> tuple[str, str]`
æ ¹æ®ç³»ç»ŸçŠ¶æ€è‡ªåŠ¨ç”Ÿæˆä¼˜åŒ–å»ºè®®

**å‚æ•°:**
- `status`: ç³»ç»ŸçŠ¶æ€å­—å…¸ï¼ˆæ¥è‡ª`get_status()`ï¼‰

**è¿”å›å€¼:**
- `(conv_id, advice)`: å¯¹è¯IDå’Œå»ºè®®å†…å®¹

**ç¤ºä¾‹:**
```python
status = get_status()
conv_id, advice = auto_advise(status)
print(f"å¯¹è¯ID: {conv_id}")
print(f"å»ºè®®: {advice}")
```

#### `user_advise(conv_id: str, text: str) -> str`
å¤„ç†ç”¨æˆ·ä¸AIçš„å¯¹è¯

**å‚æ•°:**
- `conv_id`: å¯¹è¯ID
- `text`: ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬

**è¿”å›å€¼:**
- AIçš„å›å¤å†…å®¹

**ç¤ºä¾‹:**
```python
response = user_advise(conv_id, "å¦‚ä½•ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Ÿ")
print(response)
```

### å†å²ç®¡ç† (`history_manager.py`)

#### `get_history_list() -> List[Dict[str, str]]`
è·å–å†å²å¯¹è¯åˆ—è¡¨

**è¿”å›å€¼:**
```python
[
    {
        "id": "20241025_143022_123456",
        "title": "CPUæ€§èƒ½åˆ†æ",
        "timestamp": "2024-10-25 14:30:22"
    },
    ...
]
```

#### `create_conversation(title: str = None) -> str`
åˆ›å»ºæ–°å¯¹è¯

**è¿”å›å€¼:** æ–°å¯¹è¯çš„ID

#### `switch_conversation(conv_id: str) -> List[Dict[str, str]]`
åˆ‡æ¢åˆ°æŒ‡å®šå¯¹è¯

**è¿”å›å€¼:** æ¶ˆæ¯åˆ—è¡¨
```python
[
    {
        "role": "user",
        "content": "å¦‚ä½•ä¼˜åŒ–CPUï¼Ÿ",
        "timestamp": "2024-10-25 14:30:22"
    },
    {
        "role": "assistant",
        "content": "æ‚¨å¯ä»¥å°è¯•...",
        "timestamp": "2024-10-25 14:30:25"
    }
]
```

## âš™ï¸ é…ç½®è¯´æ˜

`config/settings.json` é…ç½®é¡¹ï¼š

```json
{
  "llm": {
    "api_key": "your-api-key",      // APIå¯†é’¥
    "model": "gpt-3.5-turbo",       // æ¨¡å‹åç§°
    "base_url": "https://...",      // APIåŸºç¡€URL
    "temperature": 0.7,             // æ¸©åº¦å‚æ•°
    "max_tokens": 1000              // æœ€å¤§tokenæ•°
  },
  "monitoring": {
    "update_interval": 5,           // æ›´æ–°é—´éš”(ç§’)
    "cpu_warning_threshold": 80,    // CPUå‘Šè­¦é˜ˆå€¼
    "memory_warning_threshold": 85, // å†…å­˜å‘Šè­¦é˜ˆå€¼
    "disk_warning_threshold": 90    // ç£ç›˜å‘Šè­¦é˜ˆå€¼
  },
  "data": {
    "history_path": "./data/history.json",  // å†å²è®°å½•è·¯å¾„
    "max_conversations": 100                 // æœ€å¤§å¯¹è¯æ•°
  }
}
```

## ğŸ”§ é«˜çº§ç”¨æ³•

### ä½¿ç”¨ç±»æ¥å£

```python
from core.advisor import Advisor
from core.history_manager import HistoryManager
from core.system_monitor import get_status

# è‡ªå®šä¹‰é…ç½®
advisor = Advisor("./my_config.json")
history_mgr = HistoryManager("./my_history.json")

# è·å–çŠ¶æ€å¹¶ç”Ÿæˆå»ºè®®
status = get_status()
conv_id, advice = advisor.auto_advise(status)

# ç®¡ç†å¯¹è¯
messages = history_mgr.switch_conversation(conv_id)
history_mgr.add_message(conv_id, "user", "æ–°é—®é¢˜")
```

### è‡ªå®šä¹‰å‘Šè­¦é˜ˆå€¼

```python
from core import get_status, check_alerts

status = get_status()
custom_thresholds = {
    "cpu": 70,
    "memory": 80,
    "disk": 85
}
alerts = check_alerts(status, custom_thresholds)
for alert in alerts:
    print(alert)
```

### è·å–è¿›ç¨‹ä¿¡æ¯

```python
from core import get_top_processes

processes = get_top_processes(limit=10)
for proc in processes:
    print(f"{proc['name']}: CPU={proc['cpu']}%, Memory={proc['memory']}%")
```

## ğŸ¨ UIé›†æˆå»ºè®®

æ ¸å¿ƒåŠŸèƒ½å·²å®Œæˆï¼Œå¯ä»¥è½»æ¾é›†æˆåˆ°ä»»ä½•UIæ¡†æ¶ï¼š

### Streamlitç¤ºä¾‹

```python
import streamlit as st
from core import get_status, auto_advise, user_advise, get_history_list

# æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
status = get_status()
st.metric("CPU", f"{status['cpu']}%")
st.metric("å†…å­˜", f"{status['memory']}%")

# è·å–å»ºè®®æŒ‰é’®
if st.button("è·å–å»ºè®®"):
    conv_id, advice = auto_advise(status)
    st.session_state.current_conv = conv_id
    st.write(advice)

# å¯¹è¯è¾“å…¥
if user_input := st.chat_input("è¾“å…¥æ¶ˆæ¯"):
    response = user_advise(st.session_state.current_conv, user_input)
    st.write(response)
```

### Flaskç¤ºä¾‹

```python
from flask import Flask, jsonify, request
from core import get_status, auto_advise, user_advise

app = Flask(__name__)

@app.route('/api/status')
def api_status():
    return jsonify(get_status())

@app.route('/api/advise', methods=['POST'])
def api_advise():
    status = get_status()
    conv_id, advice = auto_advise(status)
    return jsonify({"conv_id": conv_id, "advice": advice})

@app.route('/api/chat', methods=['POST'])
def api_chat():
    data = request.json
    response = user_advise(data['conv_id'], data['text'])
    return jsonify({"response": response})
```

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **API Keyå®‰å…¨**: ä¸è¦å°†API Keyæäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿ
2. **ä¾èµ–å®‰è£…**: ç¡®ä¿å®‰è£…äº†`psutil`å’Œ`openai`åº“
3. **æƒé™è¦æ±‚**: æŸäº›ç³»ç»Ÿç›‘æ§åŠŸèƒ½å¯èƒ½éœ€è¦ç®¡ç†å‘˜æƒé™
4. **é”™è¯¯å¤„ç†**: æ‰€æœ‰å‡½æ•°éƒ½æœ‰åŸºæœ¬çš„é”™è¯¯å¤„ç†ï¼Œä¼šè¿”å›é”™è¯¯ä¿¡æ¯è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸

## ğŸ”® æ‰©å±•æ–¹å‘

- [ ] æ”¯æŒæ›´å¤šLLMæä¾›å•†ï¼ˆClaudeã€é€šä¹‰åƒé—®ç­‰ï¼‰
- [ ] æ·»åŠ GPU/æ¸©åº¦ç›‘æ§
- [ ] å®ç°è‡ªåŠ¨å‘Šè­¦æ¨é€ï¼ˆé‚®ä»¶/webhookï¼‰
- [ ] æ•°æ®åº“æ”¯æŒï¼ˆSQLite/PostgreSQLï¼‰
- [ ] æ”¯æŒæ’ä»¶ç³»ç»Ÿ
- [ ] æ€§èƒ½æ•°æ®å¯è§†åŒ–
- [ ] å¯¼å‡ºæŠ¥å‘ŠåŠŸèƒ½

## ğŸ“„ è®¸å¯è¯

MIT License

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼
